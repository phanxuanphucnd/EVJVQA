{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a29487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucpx/miniconda3/envs/phucpx/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "from evaluate_metrics import compute_f1, compute_avg_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5688ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test/evjvqa_public_test-lang-qtype-answer.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd67179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ebb07227b349239931f3124c208c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5015, 5015, 5015)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_annotations = test_data['annotations']\n",
    "\n",
    "qid2lang = {}\n",
    "qid2qtype = {}\n",
    "\n",
    "for anno in tqdm(test_annotations):\n",
    "    qid2lang[str(anno['id'])] = anno['language']\n",
    "    qid2qtype[str(anno['id'])] = anno['question_type']\n",
    "    \n",
    "len(test_annotations), len(qid2lang), len(qid2qtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a8a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./outputs/groundtruth_results.json', 'r', encoding='utf-8') as f:\n",
    "    gt_results = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bfb63",
   "metadata": {},
   "source": [
    "## MT5 + VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32ed2e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- EN -------------------\n",
      "Metrics of Language=en: F1 = 0.18036668552330218 and Bleu = 0.12762038026689043\n",
      "------------------- VI -------------------\n",
      "Metrics of Language=vi: F1 = 0.2697203135337372 and Bleu = 0.1965703409687105\n",
      "------------------- JA -------------------\n",
      "Metrics of Language=ja: F1 = 0.28681220185811296 and Bleu = 0.22247196627623678\n"
     ]
    }
   ],
   "source": [
    "with open('./outputs/results-mt5-vit.json', 'r', encoding='utf-8') as f:\n",
    "    mt5vit_results = json.load(f)\n",
    "\n",
    "sep_qtype = False\n",
    "languages = ['en', 'vi', 'ja']\n",
    "# question_types = list(set(qid2qtype.values()))\n",
    "question_types = ['HOW_MANY', 'WHAT_COLOR', 'WHERE', 'WHO', 'HOW', 'WHAT_IS', 'WHAT_DO', 'WHICH', 'OTHERS']\n",
    "\n",
    "for lang in languages:\n",
    "    pred = {}\n",
    "    grth = {}\n",
    "    print(f'------------------- {lang.upper()} -------------------')\n",
    "    if sep_qtype:\n",
    "        for qtype in question_types:\n",
    "            pred = {}\n",
    "            grth = {}\n",
    "            for k, v in mt5vit_results.items():\n",
    "                if qid2lang[k] == lang and qid2qtype[k] == qtype:\n",
    "                    pred[k] = v\n",
    "                    grth[k] = gt_results[k]\n",
    "            \n",
    "            f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "            bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "            print(f\"Metrics of Language={lang} - Question Type={qtype}: F1 = {f1} and Bleu = {bleu}\")\n",
    "    \n",
    "        print(f'------------------- END -------------------')\n",
    "    else:\n",
    "        for k, v in mt5vit_results.items():\n",
    "            if qid2lang[k] == lang:\n",
    "                pred[k] = v\n",
    "                grth[k] = gt_results[k]\n",
    "\n",
    "        f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "        bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "        print(f\"Metrics of Language={lang}: F1 = {f1} and Bleu = {bleu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f66508",
   "metadata": {},
   "source": [
    "## MT5 + CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76fff2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- EN -------------------\n",
      "Metrics of Language=en - Question Type=HOW_MANY: F1 = 0.13339016958487496 and Bleu = 0.15230238711372088\n",
      "Metrics of Language=en - Question Type=WHAT_COLOR: F1 = 0.18867264810661036 and Bleu = 0.11885855015466021\n",
      "Metrics of Language=en - Question Type=WHERE: F1 = 0.21169268100878802 and Bleu = 0.10593184382072081\n",
      "Metrics of Language=en - Question Type=WHO: F1 = 0.1892021740442793 and Bleu = 0.10434442536656838\n",
      "Metrics of Language=en - Question Type=HOW: F1 = 0.12821011168762037 and Bleu = 0.05377825721395391\n",
      "Metrics of Language=en - Question Type=WHAT_IS: F1 = 0.13199692708824523 and Bleu = 0.07882378140220024\n",
      "Metrics of Language=en - Question Type=WHAT_DO: F1 = 0.10929560189096035 and Bleu = 0.042158015981437355\n",
      "Metrics of Language=en - Question Type=WHICH: F1 = 0.33082651111143757 and Bleu = 0.27822888234924353\n",
      "Metrics of Language=en - Question Type=OTHERS: F1 = 0.1278827139938251 and Bleu = 0.07079791924006913\n",
      "------------------- END -------------------\n",
      "------------------- VI -------------------\n",
      "Metrics of Language=vi - Question Type=HOW_MANY: F1 = 0.3226552377634087 and Bleu = 0.16155048696026597\n",
      "Metrics of Language=vi - Question Type=WHAT_COLOR: F1 = 0.40654149524000066 and Bleu = 0.3140880050066984\n",
      "Metrics of Language=vi - Question Type=WHERE: F1 = 0.22488091441096555 and Bleu = 0.13371101002266703\n",
      "Metrics of Language=vi - Question Type=WHO: F1 = 0.09260204939062008 and Bleu = 0.04747292196012159\n",
      "Metrics of Language=vi - Question Type=HOW: F1 = 0.228032611646057 and Bleu = 0.09900029824613055\n",
      "Metrics of Language=vi - Question Type=WHAT_IS: F1 = 0.1497049573520162 and Bleu = 0.07133530225872844\n",
      "Metrics of Language=vi - Question Type=WHAT_DO: F1 = 0.05482064627265866 and Bleu = 0.023561174513035257\n",
      "Metrics of Language=vi - Question Type=WHICH: F1 = nan and Bleu = 0.0\n",
      "Metrics of Language=vi - Question Type=OTHERS: F1 = 0.15490009884617822 and Bleu = 0.09968288929047207\n",
      "------------------- END -------------------\n",
      "------------------- JA -------------------\n",
      "Metrics of Language=ja - Question Type=HOW_MANY: F1 = 0.2942098438608053 and Bleu = 0.2912822913062508\n",
      "Metrics of Language=ja - Question Type=WHAT_COLOR: F1 = 0.36583614367806144 and Bleu = 0.283937626450694\n",
      "Metrics of Language=ja - Question Type=WHERE: F1 = 0.1653856942823571 and Bleu = 0.1258696580195471\n",
      "Metrics of Language=ja - Question Type=WHO: F1 = 0.24777099545493608 and Bleu = 0.20185240920184133\n",
      "Metrics of Language=ja - Question Type=HOW: F1 = 0.17284031225978488 and Bleu = 0.13813466055623344\n",
      "Metrics of Language=ja - Question Type=WHAT_IS: F1 = 0.22222965218576488 and Bleu = 0.16522180658710825\n",
      "Metrics of Language=ja - Question Type=WHAT_DO: F1 = 0.21806644039659814 and Bleu = 0.22553749319029942\n",
      "Metrics of Language=ja - Question Type=WHICH: F1 = 0.3299108572434454 and Bleu = 0.3605469765695783\n",
      "Metrics of Language=ja - Question Type=OTHERS: F1 = 0.1485172414746545 and Bleu = 0.12084592643203246\n",
      "------------------- END -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucpx/vinbdi/EVJVQA/evaluate_metrics.py:142: RuntimeWarning: Mean of empty slice.\n",
      "  return np.array(scores).mean()\n",
      "/home/phucpx/miniconda3/envs/phucpx/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "with open('./outputs/results-mt5-clip.json', 'r', encoding='utf-8') as f:\n",
    "    mt5vit_results = json.load(f)\n",
    "\n",
    "sep_qtype = True\n",
    "languages = ['en', 'vi', 'ja']\n",
    "# question_types = list(set(qid2qtype.values()))\n",
    "question_types = ['HOW_MANY', 'WHAT_COLOR', 'WHERE', 'WHO', 'HOW', 'WHAT_IS', 'WHAT_DO', 'WHICH', 'OTHERS']\n",
    "\n",
    "for lang in languages:\n",
    "    pred = {}\n",
    "    grth = {}\n",
    "    print(f'------------------- {lang.upper()} -------------------')\n",
    "    if sep_qtype:\n",
    "        for qtype in question_types:\n",
    "            pred = {}\n",
    "            grth = {}\n",
    "            for k, v in mt5vit_results.items():\n",
    "                if qid2lang[k] == lang and qid2qtype[k] == qtype:\n",
    "                    pred[k] = v\n",
    "                    grth[k] = gt_results[k]\n",
    "            \n",
    "            f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "            bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "            print(f\"Metrics of Language={lang} - Question Type={qtype}: F1 = {f1} and Bleu = {bleu}\")\n",
    "    \n",
    "        print(f'------------------- END -------------------')\n",
    "    else:\n",
    "        for k, v in mt5vit_results.items():\n",
    "            if qid2lang[k] == lang:\n",
    "                pred[k] = v\n",
    "                grth[k] = gt_results[k]\n",
    "\n",
    "        f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "        bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "        print(f\"Metrics of Language={lang}: F1 = {f1} and Bleu = {bleu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9d8e4",
   "metadata": {},
   "source": [
    "## MT5 + DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bae593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eda841de",
   "metadata": {},
   "source": [
    "## MT5 + BEiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f4a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- EN -------------------\n",
      "Metrics of Language=en - Question Type=HOW_MANY: F1 = 0.13053295067253193 and Bleu = 0.1470569420457975\n",
      "Metrics of Language=en - Question Type=WHAT_COLOR: F1 = 0.20336276899817407 and Bleu = 0.12395571180106006\n",
      "Metrics of Language=en - Question Type=WHERE: F1 = 0.17593017702369135 and Bleu = 0.0746543972312971\n",
      "Metrics of Language=en - Question Type=WHO: F1 = 0.1871823731823732 and Bleu = 0.08006352108680244\n",
      "Metrics of Language=en - Question Type=HOW: F1 = 0.21282214517508635 and Bleu = 0.05022458593174603\n",
      "Metrics of Language=en - Question Type=WHAT_IS: F1 = 0.1307706030307934 and Bleu = 0.06293572549477212\n",
      "Metrics of Language=en - Question Type=WHAT_DO: F1 = 0.10428357449841824 and Bleu = 0.03382330264840466\n",
      "Metrics of Language=en - Question Type=WHICH: F1 = 0.24861698557398054 and Bleu = 0.1210749153495035\n",
      "Metrics of Language=en - Question Type=OTHERS: F1 = 0.12334489070600181 and Bleu = 0.06517309386845564\n",
      "------------------- END -------------------\n",
      "------------------- VI -------------------\n",
      "Metrics of Language=vi - Question Type=HOW_MANY: F1 = 0.2392930303208188 and Bleu = 0.10955823946843675\n",
      "Metrics of Language=vi - Question Type=WHAT_COLOR: F1 = 0.393716902999141 and Bleu = 0.20968343656691316\n",
      "Metrics of Language=vi - Question Type=WHERE: F1 = 0.18537219565032864 and Bleu = 0.09563813301826149\n",
      "Metrics of Language=vi - Question Type=WHO: F1 = 0.21646602988514754 and Bleu = 0.08692662490645071\n",
      "Metrics of Language=vi - Question Type=HOW: F1 = 0.20132389268517403 and Bleu = 0.06595308780112631\n",
      "Metrics of Language=vi - Question Type=WHAT_IS: F1 = 0.1105556883203942 and Bleu = 0.06220176424491791\n",
      "Metrics of Language=vi - Question Type=WHAT_DO: F1 = 0.05138977797801327 and Bleu = 0.026143931644044875\n",
      "Metrics of Language=vi - Question Type=WHICH: F1 = nan and Bleu = 0.0\n",
      "Metrics of Language=vi - Question Type=OTHERS: F1 = 0.11985265694226531 and Bleu = 0.06633233601308255\n",
      "------------------- END -------------------\n",
      "------------------- JA -------------------\n",
      "Metrics of Language=ja - Question Type=HOW_MANY: F1 = 0.3495107736006434 and Bleu = 0.27676793118543114\n",
      "Metrics of Language=ja - Question Type=WHAT_COLOR: F1 = 0.3586023591476646 and Bleu = 0.28812287794196123\n",
      "Metrics of Language=ja - Question Type=WHERE: F1 = 0.20052901458110167 and Bleu = 0.14337210818519644\n",
      "Metrics of Language=ja - Question Type=WHO: F1 = 0.19011003281358493 and Bleu = 0.15873473307747007\n",
      "Metrics of Language=ja - Question Type=HOW: F1 = 0.3635394256967455 and Bleu = 0.330601256832029\n",
      "Metrics of Language=ja - Question Type=WHAT_IS: F1 = 0.2917391772706446 and Bleu = 0.2284811625775387\n",
      "Metrics of Language=ja - Question Type=WHAT_DO: F1 = 0.3182454202765805 and Bleu = 0.26922535714751933\n",
      "Metrics of Language=ja - Question Type=WHICH: F1 = 0.33803750792577386 and Bleu = 0.32833618350426486\n",
      "Metrics of Language=ja - Question Type=OTHERS: F1 = 0.20347604582848366 and Bleu = 0.19293818061683876\n",
      "------------------- END -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucpx/vinbdi/EVJVQA/evaluate_metrics.py:142: RuntimeWarning: Mean of empty slice.\n",
      "  return np.array(scores).mean()\n",
      "/home/phucpx/miniconda3/envs/phucpx/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "with open('./outputs/results-beit-last.json', 'r', encoding='utf-8') as f:\n",
    "    mt5beit_results = json.load(f)\n",
    "\n",
    "sep_qtype = True\n",
    "languages = ['en', 'vi', 'ja']\n",
    "# question_types = list(set(qid2qtype.values()))\n",
    "question_types = ['HOW_MANY', 'WHAT_COLOR', 'WHERE', 'WHO', 'HOW', 'WHAT_IS', 'WHAT_DO', 'WHICH', 'OTHERS']\n",
    "\n",
    "for lang in languages:\n",
    "    pred = {}\n",
    "    grth = {}\n",
    "    print(f'------------------- {lang.upper()} -------------------')\n",
    "    if sep_qtype:\n",
    "        for qtype in question_types:\n",
    "            pred = {}\n",
    "            grth = {}\n",
    "            for k, v in mt5beit_results.items():\n",
    "                if qid2lang[k] == lang and qid2qtype[k] == qtype:\n",
    "                    pred[k] = v\n",
    "                    grth[k] = gt_results[k]\n",
    "            \n",
    "            f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "            bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "            print(f\"Metrics of Language={lang} - Question Type={qtype}: F1 = {f1} and Bleu = {bleu}\")\n",
    "    \n",
    "        print(f'------------------- END -------------------')\n",
    "    else:\n",
    "        for k, v in mt5beit_results.items():\n",
    "            if qid2lang[k] == lang:\n",
    "                pred[k] = v\n",
    "                grth[k] = gt_results[k]\n",
    "\n",
    "        f1 = compute_f1(a_gold=grth, a_pred=pred)\n",
    "        bleu = compute_avg_bleu(a_gold=grth, a_pred=pred)\n",
    "            \n",
    "        print(f\"Metrics of Language={lang}: F1 = {f1} and Bleu = {bleu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8524e",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af1a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train/evjvqa_train_lang_qtype-detailed.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "train_annotations = train_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ebbe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2031a6be6c734d479a1affc6cb09289f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12121\n"
     ]
    }
   ],
   "source": [
    "subtrain_annotations = []\n",
    "\n",
    "LIST_QTYPES = ['WHAT_IS', 'WHO', 'WHERE', 'HOW_MANY']\n",
    "\n",
    "for anno in tqdm(train_annotations):\n",
    "    if anno['question_type'] in LIST_QTYPES:\n",
    "        subtrain_annotations.append(anno)\n",
    "        \n",
    "print(len(subtrain_annotations))\n",
    "\n",
    "subtrain_dict = {\n",
    "    'images': train_data['images'],\n",
    "    'annotations': subtrain_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303e04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train/evjvqa-subtrain-obj.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(subtrain_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7849161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4564f2f59c024a94bbe6f50877a9ea61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test/evjvqa_public_test-lang-qtype-answer.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "test_annotations = test_data['annotations']\n",
    "\n",
    "subtest_annotations = []\n",
    "\n",
    "LIST_QTYPES = ['WHAT_IS', 'WHO', 'WHERE', 'HOW_MANY']\n",
    "\n",
    "for anno in tqdm(test_annotations):\n",
    "    if anno['question_type'] in LIST_QTYPES:\n",
    "        subtest_annotations.append(anno)\n",
    "        \n",
    "print(len(subtest_annotations))\n",
    "\n",
    "subtest_dict = {\n",
    "    'images': test_data['images'],\n",
    "    'annotations': subtest_annotations\n",
    "}\n",
    "\n",
    "with open('./data/test/evjvqa-subtest-obj.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(subtest_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ca40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phucpx",
   "language": "python",
   "name": "phucpx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
