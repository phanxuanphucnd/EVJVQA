{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd3c6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucpx/miniconda3/envs/phucpx/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "/home/phucpx/miniconda3/envs/phucpx/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import jnc\n",
    "import json\n",
    "import httpx\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "from num2words import num2words\n",
    "from googletrans import Translator\n",
    "from tqdm.autonotebook import tqdm\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e2a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = httpx.Timeout(30) \n",
    "gg_translator = Translator(timeout=timeout)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "vi_num2words_dict = {\n",
    "    0: 'không',\n",
    "    1: 'một',\n",
    "    2: 'hai',\n",
    "    3: 'ba',\n",
    "    4: 'bốn',\n",
    "    5: 'năm',\n",
    "    6: 'sáu',\n",
    "    7: 'bảy',\n",
    "    8: 'tám',\n",
    "    9: 'chín',\n",
    "    10: 'mười'\n",
    "}\n",
    "vi_words2num_dict = {\n",
    "    'không': 0,\n",
    "    'một': 1,\n",
    "    'hai': 2,\n",
    "    'ba': 3,\n",
    "    'bốn': 4,\n",
    "    'năm': 5,\n",
    "    'sáu': 6,\n",
    "    'bảy': 7,\n",
    "    'tám': 8,\n",
    "    'chín': 9,\n",
    "    'mười': 10\n",
    "}\n",
    "\n",
    "en_words2num_dict = {\n",
    "    'zero': 0,\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5,\n",
    "    'six': 6,\n",
    "    'seven': 7,\n",
    "    'eight': 8,\n",
    "    'nine': 9,\n",
    "    'ten': 10\n",
    "}\n",
    "\n",
    "no_ja_dict = {\n",
    "    '一': 1,\n",
    "    '二': 2,\n",
    "    '三': 3,\n",
    "    \n",
    "}\n",
    "\n",
    "list_numbers = [\n",
    "    'không', 'một', 'hai', 'ba', 'bốn', 'năm', 'sáu', 'bảy', 'tám', 'chín', 'mười',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "    'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'a ', 'an '\n",
    "]\n",
    "\n",
    "def remove_punc(text):\n",
    "    text = text.lower()\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "\n",
    "def get_samples_by_id(image_id, annotations, question_type):\n",
    "    return_samples = []\n",
    "    for anno in annotations:\n",
    "        if anno['image_id'] == image_id:\n",
    "            if anno['question_type'] == question_type:\n",
    "                return_samples.append(anno)\n",
    "\n",
    "    return return_samples\n",
    "\n",
    "def get_by_language(annotations, language='en'):\n",
    "    tmp = []\n",
    "    for anno in annotations:\n",
    "        if anno['language'] == language:\n",
    "            tmp.append(anno)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def get_idx_in_list(idx, list_triple):\n",
    "    for triple in list_triple:\n",
    "        if idx in triple:\n",
    "            return triple\n",
    "    \n",
    "    return None\n",
    "\n",
    "def check_token_number(token):\n",
    "    try:\n",
    "        flag = str(jnc.ja_to_arabic(token)).isdigit()\n",
    "    except:\n",
    "        flag = False\n",
    "\n",
    "    if token in list_numbers or flag:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fc3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_questions = []\n",
    "\n",
    "with open('./data/test/evjvqa_public_test-lang-qtype-answer.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "test_annotations = test_data['annotations']\n",
    "\n",
    "\n",
    "with open('./outputs/public-test/results-ofa-huge-finetuned.json', 'r', encoding='utf-8') as f:\n",
    "    ofa = json.load(f)\n",
    "\n",
    "\n",
    "with open('./outputs/public-test/results-vit-mt5.json', 'r', encoding='utf-8') as f:\n",
    "    mt5vit = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6447f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test/group.md', 'r', encoding='utf-8') as f:\n",
    "    group_ids = [ast.literal_eval(line.strip()) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5581a35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 2, 4], list)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_ids[0], type(group_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77129cbe",
   "metadata": {},
   "source": [
    "## HOW_MANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db19e20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c3a25441aa45cf9d2dc3a4804ed2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 が1人います\n",
      "128 が1人います\n",
      "------\n",
      "160 村の入口をくぐる人は1人います\n",
      "160 村の入口をくぐる人は1人います\n",
      "------\n",
      "291 家の中に三人がいます。\n",
      "291 家の中に3人がいます。\n",
      "------\n",
      "732 お店の前に2人座っています\n",
      "732 お店の前に2人座っています\n",
      "------\n",
      "1008 tシャツを買いに来る2人\n",
      "1008 tシャツを買いに来る2人\n",
      "------\n",
      "1010 一人\n",
      "1010 1人\n",
      "------\n",
      "1011 二人\n",
      "1011 2人\n",
      "------\n",
      "1243 女の子は一人で立っています\n",
      "1243 女の子は1人で立っています\n",
      "------\n",
      "1590 赤い服を着た女性が1人います\n",
      "1590 赤い服を着た女性が1人います\n",
      "------\n",
      "1598 一人で行く\n",
      "1598 1人で行く\n",
      "------\n",
      "1604 一人です\n",
      "1604 1人です\n",
      "------\n",
      "1918 電話アクセサリー店には3人の顧客が来ます\n",
      "1918 電話アクセサリー店には3人の顧客が来ます\n",
      "------\n",
      "1966 お店で3人\n",
      "1966 お店で3人\n",
      "------\n",
      "2014 飛行機の下で写真を撮るために立っている1人\n",
      "2014 飛行機の下で写真を撮るために立っている1人\n",
      "------\n",
      "2453 誰も果物狩りに来ませんでした\n",
      "2453 誰も果物狩りに来ませんでした\n",
      "------\n",
      "3074 三人\n",
      "3074 3人\n",
      "------\n",
      "3905 3人\n",
      "3905 3人\n",
      "------\n",
      "3955 出かけた女性が二人います。\n",
      "3955 出かけた女性が2人います。\n",
      "------\n",
      "4240 眼鏡売り場で二人が売っています。\n",
      "4240 眼鏡売り場で2人が売っています。\n",
      "------\n",
      "4887 牛乳屋台に立っている2人がいます\n",
      "4887 牛乳屋台に立っている2人がいます\n",
      "------\n",
      "4902 右隅の壁には6枚の絵がかかっています\n",
      "4902 右隅の壁には6枚の絵がかかっています\n",
      "------\n",
      "4938 一人で\n",
      "4938 1人で\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "answer_dict = {}\n",
    "\n",
    "for i, anno in tqdm(enumerate(test_annotations)):\n",
    "    question_type = anno['question_type']\n",
    "    question = anno['question']\n",
    "    \n",
    "    if question_type == 'HOW_MANY':\n",
    "        idx = anno['id']\n",
    "        if anno['language'] == 'en':\n",
    "            answer = ofa[str(idx)]\n",
    "            if len(answer.split()) == 2:\n",
    "                answer = answer.replace('the ', ' ').strip() \n",
    "            if '⁄' in answer: \n",
    "                tmp_ans = answer.split('⁄')\n",
    "                ans = []\n",
    "                for w in tmp_ans:\n",
    "                    ans.append(num2words(int(w)).replace('-', ' '))\n",
    "                \n",
    "                answer = ' '.join(ans)\n",
    "\n",
    "            answer_dict[idx] = answer\n",
    "        \n",
    "        elif anno['language'] == 'vi':\n",
    "            similar_ids = get_idx_in_list(idx, group_ids)[0]\n",
    "            \n",
    "            answer = mt5vit[str(idx)]\n",
    "            \n",
    "            if similar_ids is not None:\n",
    "                en_answer = answer_dict[similar_ids]\n",
    "                vi_answer = gg_translator.translate(en_answer, src='en', dest=anno['language']).text\n",
    "                vi_answer = vi_answer.replace('số', ' ').strip()\n",
    "                \n",
    "                if 'bao nhiêu' in question:\n",
    "                    if \"năm\" in answer and len(vi_answer.split()) == 1:\n",
    "                        tmp_answer = answer.replace('năm', vi_answer)\n",
    "                    else:\n",
    "                        tmp_answer = question.replace(\"?\", '').replace(\"bao nhiêu\", vi_answer)\n",
    "            \n",
    "#                 tokens = answer.split()\n",
    "#                 for j in range(len(tokens)):\n",
    "#                     if tokens[j] in list_numbers:\n",
    "#                         tokens[j] = vi_answer\n",
    "\n",
    "#                 answer =  ' '.join(tokens)\n",
    "                answer = tmp_answer\n",
    "            \n",
    "            answer_dict[idx] = answer\n",
    "        \n",
    "        elif anno['language'] == 'ja':\n",
    "            similar_ids = get_idx_in_list(idx, group_ids)[0]\n",
    "            \n",
    "            answer = mt5vit[str(idx)]\n",
    "            \n",
    "            answer_dict[idx] = answer\n",
    "            \n",
    "            if similar_ids is not None:\n",
    "                en_answer = answer_dict[similar_ids]\n",
    "                try:\n",
    "                    digit_answer = en_words2num_dict[en_answer]\n",
    "\n",
    "                    tokens = list(answer)\n",
    "                    for j in range(len(tokens)):\n",
    "                        if check_token_number(str(tokens[j])):\n",
    "                            tokens[j] = str(digit_answer)\n",
    "\n",
    "                    answer =  ''.join(tokens)\n",
    "                except:\n",
    "                    print(idx, answer)\n",
    "#                     if '人' in answer:\n",
    "#                         tokens = list(answer)\n",
    "#                         for x in range(len(tokens)):\n",
    "#                             if tokens[x] == '人':\n",
    "#                                 tokens[x - 1] = str(no_ja_dict.get(tokens[x - 1], tokens[x-1]))\n",
    "                                \n",
    "#                         answer = ''.join(tokens)\n",
    "                    \n",
    "#                     print(idx, answer)\n",
    "#                     print('------')\n",
    "\n",
    "            answer_dict[idx] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718779d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./outputs/public-test/results-how-many-vit-ofa.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(answer_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df66257",
   "metadata": {},
   "source": [
    "## WHAT_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9a95f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ca44139244f16867a2c72f844e17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_dict = {}\n",
    "\n",
    "for i, anno in tqdm(enumerate(test_annotations)):\n",
    "    question_type = anno['question_type']\n",
    "    \n",
    "    if question_type == 'WHAT_COLOR':\n",
    "        idx = anno['id']\n",
    "        if anno['language'] == 'en':\n",
    "            answer = ofa[str(idx)]\n",
    "#             if len(answer.split()) == 2:\n",
    "            answer = answer.replace('the ', ' ').strip() \n",
    "\n",
    "            answer_dict[idx] = answer\n",
    "            \n",
    "with open('./outputs/public-test/results-what_color-ofa.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(answer_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ab27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phucpx",
   "language": "python",
   "name": "phucpx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
